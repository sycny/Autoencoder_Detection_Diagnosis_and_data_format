{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8acfe141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io import loadmat #load mat data on python\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.layers import Conv1D, Conv1DTranspose\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a6b2693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoderextract2D(x_train):\n",
    "\n",
    "    ## define the encoder\n",
    "    encoder = Input(shape=(x_train.shape[1], x_train.shape[2],x_train.shape[3]))\n",
    "    e = Conv2D(filters=128, kernel_size=(5,5), padding=\"same\", strides=7, activation=\"relu\")(encoder)\n",
    "    e = Conv2D(filters=64, kernel_size=(5,5), padding=\"same\", strides=3, activation=\"relu\")(e)\n",
    "    e = Conv2D(filters=16, kernel_size=(5,5), padding=\"same\", strides=1, activation=\"relu\")(e)\n",
    "    ## bottleneck layer\n",
    "    n_bottleneck = 8\n",
    "    ## defining it with a name to extract it later\n",
    "    bottleneck_layer = \"bottleneck_layer\"\n",
    "    # can also be defined with an activation function, relu for instance\n",
    "    bottleneck = Dense(n_bottleneck, name=bottleneck_layer)(e)\n",
    "\n",
    "    ## define the decoder (in reverse)\n",
    "    decoder = Conv2DTranspose(filters=4, kernel_size=(5,5), padding=\"same\", strides=3, activation=\"relu\")(bottleneck)\n",
    "    #decoder = Conv2DTranspose(filters=2, kernel_size=(5,5), padding=\"same\", strides=3, activation=\"relu\")(decoder)\n",
    "    decoder = Conv2DTranspose(filters=2, kernel_size=(5,5), padding=\"same\", strides=7, activation=\"relu\")(decoder)\n",
    "    ## output layer\n",
    "    output = Conv2DTranspose(filters=1, kernel_size=(5,5), padding=\"same\")(decoder)\n",
    "    ## model\n",
    "    model = Model(inputs=encoder, outputs=output)\n",
    "    encoder = Model(inputs=model.input, outputs=bottleneck)\n",
    "    model.summary()\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    history = model.fit(\n",
    "    x_train,\n",
    "    x_train,\n",
    "    batch_size = 4,\n",
    "    epochs = 100,\n",
    "    verbose = 1,\n",
    "    validation_split=0.25\n",
    "    )\n",
    "    plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    bottneck = encoder.predict(x_train)\n",
    "    #out = np.reshape(bottneck,(-1,bottneck[2]))\n",
    "   #out = out.T\n",
    "    #bottneck.to_csv(r\"bottneck.csv\",mode = 'a',index =False)\n",
    "    return bottneck\n",
    "\n",
    "def standard(data):\n",
    "    meansdata = np.mean(data)\n",
    "    stddata = np.std(data)\n",
    "    if stddata !=0:\n",
    "        standdata = (data - meansdata) / stddata\n",
    "    else: \n",
    "        standdata = data\n",
    "    #normaldata = normaldata.reshape((normaldata.shape[0], normaldata.shape[1], 1))\n",
    "    return standdata\n",
    "def normal(data):\n",
    "    _range = np.max(data) - np.min(data)\n",
    "    if _range !=0:\n",
    "        normaldata = (data - np.min(data)) / _range\n",
    "    else:\n",
    "        normaldata = data\n",
    "    return normaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0114809",
   "metadata": {},
   "outputs": [],
   "source": [
    "samplepointcolumn = np.linspace(0,105,105,endpoint=False,dtype=int)\n",
    "discardall =[] \n",
    "for j in range(0,7):\n",
    "    discard = [j*15+3,j*15+4,j*15+5,j*15+6,j*15+7,j*15+8]#j*15+9,j*15+10,j*15+11,j*15+12,j*15+13,j*15+14\n",
    "    discardall = discardall+discard\n",
    "samplepointcolumn = np.delete(samplepointcolumn,discardall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f76ae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData = np.load( \"/Users/ycs/Desktop/PhD first year/Fall2021 Task 1/lulu code and data/PVfarm data/PMUalldatanpz.npz\" )\n",
    "x_train = np.zeros((44,63,126))\n",
    "X_train = np.zeros((44,63,126))\n",
    "j=0\n",
    "discardcase = [3, 7, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]\n",
    "for i in range(1,63):\n",
    "    if i in discardcase:\n",
    "        continue\n",
    "    Traindata = TrainData['a'][i,:,:]\n",
    "    #traindata = Traindata.values[0:105,600:720]\n",
    "    traindata = Traindata[samplepointcolumn,600:726]\n",
    "    train = np.zeros((traindata.shape[0],traindata.shape[1]))\n",
    "    for k in range(0,traindata.shape[0]):\n",
    "        train[k,:] = standard(traindata[k,:])\n",
    "        train[k,:] = normal(train[k,:])\n",
    "    #train = standard(traindata)\n",
    "    x_train[j,:,:] = train\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9957c7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(44):\n",
    "    for jj in range(7):\n",
    "        if (sum(x_train[j,2+jj*9,:])>=100):\n",
    "           #print(j,jj)\n",
    "            x_train[j,(2):]=1\n",
    "            x_train[j,(11):]=1\n",
    "            x_train[j,(20):]=1\n",
    "            x_train[j,(29):]=1\n",
    "            x_train[j,(38):]=1\n",
    "            x_train[j,(47):]=1\n",
    "            x_train[j,(56):]=1\n",
    "        else:\n",
    "            x_train[j,2+jj*9,:]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30ea5c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 16:30:11.847952: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-12 16:30:11.982937: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 63, 126, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 9, 18, 128)        3328      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 3, 6, 64)          204864    \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 6, 16)          25616     \n",
      "_________________________________________________________________\n",
      "bottleneck_layer (Dense)     (None, 3, 6, 8)           136       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 9, 18, 4)          804       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 63, 126, 2)        202       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 63, 126, 1)        51        \n",
      "=================================================================\n",
      "Total params: 235,001\n",
      "Trainable params: 235,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "9/9 [==============================] - 1s 41ms/step - loss: 0.3989 - val_loss: 0.6664\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3850 - val_loss: 0.6428\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.3668 - val_loss: 0.6110\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.3357 - val_loss: 0.5112\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.2686 - val_loss: 0.3849\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.1997 - val_loss: 0.2863\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.1627 - val_loss: 0.2291\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.1395 - val_loss: 0.1950\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.1258 - val_loss: 0.1745\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.1179 - val_loss: 0.1619\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.1115 - val_loss: 0.1558\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.1058 - val_loss: 0.1680\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.1036 - val_loss: 0.1466\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.1003 - val_loss: 0.1399\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0975 - val_loss: 0.1294\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0945 - val_loss: 0.1266\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0920 - val_loss: 0.1269\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0922 - val_loss: 0.1218\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0901 - val_loss: 0.1200\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0891 - val_loss: 0.1184\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0881 - val_loss: 0.1178\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0874 - val_loss: 0.1165\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0865 - val_loss: 0.1156\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0858 - val_loss: 0.1133\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0850 - val_loss: 0.1114\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0844 - val_loss: 0.1139\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0853 - val_loss: 0.1074\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0824 - val_loss: 0.1055\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0814 - val_loss: 0.1043\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0813 - val_loss: 0.1044\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0800 - val_loss: 0.1010\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0794 - val_loss: 0.1047\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0807 - val_loss: 0.0986\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0799 - val_loss: 0.0968\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0780 - val_loss: 0.0954\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0768 - val_loss: 0.0943\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0760 - val_loss: 0.0915\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0751 - val_loss: 0.0902\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0746 - val_loss: 0.0902\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0739 - val_loss: 0.0888\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0737 - val_loss: 0.0881\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0733 - val_loss: 0.0879\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0725 - val_loss: 0.0855\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0722 - val_loss: 0.0853\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0716 - val_loss: 0.0848\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0709 - val_loss: 0.0843\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0708 - val_loss: 0.0830\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0701 - val_loss: 0.0814\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0693 - val_loss: 0.0809\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0688 - val_loss: 0.0803\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0683 - val_loss: 0.0813\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 0.0686 - val_loss: 0.0799\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 0.0674 - val_loss: 0.0774\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0669 - val_loss: 0.0783\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0675 - val_loss: 0.0879\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0705 - val_loss: 0.0796\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0724 - val_loss: 0.0830\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0683 - val_loss: 0.0829\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0672 - val_loss: 0.0756\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0660 - val_loss: 0.0751\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0653 - val_loss: 0.0732\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0646 - val_loss: 0.0729\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0643 - val_loss: 0.0724\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0638 - val_loss: 0.0716\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0632 - val_loss: 0.0711\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0629 - val_loss: 0.0704\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.062 - 0s 23ms/step - loss: 0.0627 - val_loss: 0.0697\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0624 - val_loss: 0.0694\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0622 - val_loss: 0.0690\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0619 - val_loss: 0.0682\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0615 - val_loss: 0.0675\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0612 - val_loss: 0.0671\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0609 - val_loss: 0.0662\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0607 - val_loss: 0.0653\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.0604 - val_loss: 0.0652\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0602 - val_loss: 0.0648\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0599 - val_loss: 0.0642\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0596 - val_loss: 0.0638\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0593 - val_loss: 0.0634\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0591 - val_loss: 0.0628\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0588 - val_loss: 0.0622\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0586 - val_loss: 0.0622\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0584 - val_loss: 0.0618\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0582 - val_loss: 0.0616\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.0580 - val_loss: 0.0610\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0578 - val_loss: 0.0607\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0576 - val_loss: 0.0603\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0574 - val_loss: 0.0602\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0573 - val_loss: 0.0606\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0572 - val_loss: 0.0597\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0569 - val_loss: 0.0597\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0567 - val_loss: 0.0591\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0564 - val_loss: 0.0588\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0563 - val_loss: 0.0583\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0561 - val_loss: 0.0582\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0561 - val_loss: 0.0577\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0560 - val_loss: 0.0576\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0557 - val_loss: 0.0573\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0554 - val_loss: 0.0571\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.0553 - val_loss: 0.0569\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train2 = x_train.reshape((x_train.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
    "bott_neck2D = encoderextract2D(x_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b02cb9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 3, 6, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bott_neck2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa50184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bott_neck2 = np.reshape(bott_neck2D,(44,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d235889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd=np.zeros((44,18))\n",
    "for i in range(0,44):\n",
    "    for j in range(0,3):\n",
    "        U,svd[i,j*6:j*6+6],V = np.linalg.svd(bott_neck2D[i,j,:,:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb4bdce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 1, 1],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans3 = KMeans(n_clusters = 3, random_state = 13).fit_predict(svd)\n",
    "kmeans3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d21af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d948681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c42cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b353764c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
